{"Training/1-step TD Error": 0.04437097907066345, "Training/ClassificationLoss": 0, "Training/n-step TD Error": 0, "Training/Loss": 0.04437097907066345, "Training/ExpertAgentAgreement": 0.003407154930755496, "Training/ExpertQValues": 0.08144167810678482, "Training/OtherQValues": 0.07032717019319534, "Training/Actions": {"_type": "histogram", "values": [1036, 110, 4, 13, 2, 3, 7, 3, 3, 2, 0, 4, 0, 2, 0, 55, 25, 20, 7, 4, 16, 0, 0, 0, 0, 5, 0, 0, 39, 0, 4, 2, 5, 16, 8, 0, 5, 26, 2, 1, 2, 1, 65, 87, 7, 84, 7, 0, 3, 2, 2, 8, 0, 0, 0, 15, 3, 0, 0, 14, 15, 14, 0, 3], "bins": [0.0, 2.328125, 4.65625, 6.984375, 9.3125, 11.640625, 13.96875, 16.296875, 18.625, 20.953125, 23.28125, 25.609375, 27.9375, 30.265625, 32.59375, 34.921875, 37.25, 39.578125, 41.90625, 44.234375, 46.5625, 48.890625, 51.21875, 53.546875, 55.875, 58.203125, 60.53125, 62.859375, 65.1875, 67.515625, 69.84375, 72.171875, 74.5, 76.828125, 79.15625, 81.484375, 83.8125, 86.140625, 88.46875, 90.796875, 93.125, 95.453125, 97.78125, 100.109375, 102.4375, 104.765625, 107.09375, 109.421875, 111.75, 114.078125, 116.40625, 118.734375, 121.0625, 123.390625, 125.71875, 128.046875, 130.375, 132.703125, 135.03125, 137.359375, 139.6875, 142.015625, 144.34375, 146.671875, 149.0]}, "_runtime": 289, "_timestamp": 1634053114, "_step": 198, "grad_2.0_norm_q_net.0.weight_step": 0.016300000250339508, "grad_2.0_norm_q_net.0.bias_step": 0.000699999975040555, "grad_2.0_norm_q_net.2.weight_step": 0.023000000044703484, "grad_2.0_norm_q_net.2.bias_step": 0.003000000026077032, "grad_2.0_norm_q_net.4.weight_step": 0.028300000354647636, "grad_2.0_norm_q_net.4.bias_step": 0.013700000010430813, "grad_2.0_norm_target_net.q_net.0.weight_step": 0.38670000433921814, "grad_2.0_norm_target_net.q_net.0.bias_step": 0.08299999684095383, "grad_2.0_norm_target_net.q_net.2.weight_step": 0.804099977016449, "grad_2.0_norm_target_net.q_net.2.bias_step": 0.27160000801086426, "grad_2.0_norm_target_net.q_net.4.weight_step": 0.9405999779701233, "grad_2.0_norm_target_net.q_net.4.bias_step": 0.9656000137329102, "grad_2.0_norm_total_step": 1.6418999433517456, "epoch": 0, "trainer/global_step": 179}